{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95b32c4-701b-488e-a453-f62ba2d02c62",
   "metadata": {},
   "source": [
    "# Data camp 실습 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3cc90a-0037-498f-a468-32c07ca8574b",
   "metadata": {},
   "source": [
    "## 1. Supervised Learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2b03c-de89-4cc6-a1be-1f40f38c084b",
   "metadata": {},
   "source": [
    "### (1) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed2852b-027f-4d01-ae9c-48c94b238cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import sklearn\n",
    "sklearn.__version__\n",
    "\n",
    "# sklearn.neighbors.classification was renamed to sklearn.neighbors._classification in version 0.22.X\n",
    "# Downgrade to scikit-learn version <= 0.21.3 to fix this problem\n",
    "# (https://github.com/ageitgey/face_recognition/issues/1262)\n",
    "\n",
    "# pip install --user --upgrade scikit-learn==0.21.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44692f7-25c5-4231-b004-44e7bf8b44cb",
   "metadata": {},
   "source": [
    "#### **Classifying labels of unseen data**\n",
    "1. Build a model\n",
    "2. Model learns from the labeled data we pass to it (Labeled data = training data)\n",
    "3. pass unlabeled data to the model as input\n",
    "4. Model predicts the labels of the unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e0426-30fb-4fec-945b-1a16dd03ffeb",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbors\n",
    "* Predict the label of a data point by\n",
    "  * Looking at the **k** closest labeled data points\n",
    "  * Taking a majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fca0cad3-114d-4320-bbd1-c6113e94a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN 사용법\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "X = churn_df[['total_day_charge', 'total_eve_charge']].values\n",
    "y = churn_df['churn'].values\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(X, y)\n",
    "\n",
    "X_new = np.array([[56.8, 17.5],\n",
    "                 [24.4,24.1],\n",
    "                 [50.1, 10.9]])\n",
    "print(X_new.shape)\n",
    "\n",
    "predictions = knn.predict(X_new)\n",
    "print(f'Predictions: {predictions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27853fe-e574-4e1b-a6e2-96d6008f4dcb",
   "metadata": {},
   "source": [
    "#### Measuring model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695f3e5-9d5f-4a3b-9d21-620497f1c1f0",
   "metadata": {},
   "source": [
    "* How do we measure accuracy?\n",
    "* Could compute accuracy on the data used to fit the classifier\n",
    "* Not indicative of ability to generalize\n",
    "* Split data -> Training set / Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d10326-0a42-47bc-b0fa-356f2357d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "from sklearn.medel_selection import train_test_split\n",
    "X = churn_df.drop(\"churn\", axis=1).values\n",
    "y = churn_df[\"churn\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(X_train, y_train)\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91bdc92-6cbd-4ae4-908a-df4fa8cfecf2",
   "metadata": {},
   "source": [
    "* Model Complexity\n",
    "  * Larger k = less complex model = can cause underfitting\n",
    "  * Smaller k = more complex model = can lead to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed6fe4-db63-4da9-ac99-37d2e3494a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model complexity and over/underfitting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_accuracies = {}\n",
    "test_accuracies = {}\n",
    "neighbors = np.arange(1, 26)\n",
    "\n",
    "for neighbor in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbor)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_accuracies[neighbor] = knn.score(X_train, y_train)\n",
    "    test_accuracies[neighbor] = knn.score(X_test, y_test)\n",
    "    \n",
    "print(neighbors, '\\n', train_accuracies, '\\n', test_accuracies)\n",
    "    \n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title(\"KNN: Varying Number of Neighbors\")\n",
    "plt.plot(neighbors, train_accuracies.values(), label=\"Training Accuracy\")\n",
    "plt.plot(neighbors, test_accuracies.values(), label=\"Testing Accuracy\")\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e414d277-17d2-40af-bbd6-b2e493a3cc5f",
   "metadata": {},
   "source": [
    "### (2) Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1110b4-1ad0-4e79-b303-224e18b6a96b",
   "metadata": {},
   "source": [
    "#### Introduction to regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b578ea-3978-492c-907d-32ffea3c8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating features\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create X from the radio column's values\n",
    "X = sales_df['radio'].values\n",
    "\n",
    "# Create y from the sales column's values\n",
    "y = sales_df['sales'].values\n",
    "\n",
    "# Reshape X\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "# Check the shape of the features and targets\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69ef7e-d6cc-4c71-87cd-e510b52aac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a linear regression model\n",
    "\n",
    "# Import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create the model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "reg.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = reg.predict(X)\n",
    "\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b52700b-b5c8-443b-9df4-beaaf1365d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing a linear regression model\n",
    "\n",
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(X, y, color=\"blue\")\n",
    "\n",
    "# Create line plot\n",
    "plt.plot(X, predictions, color=\"red\")\n",
    "plt.xlabel(\"Radio Expenditure ($)\")\n",
    "plt.ylabel(\"Sales ($)\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620794c9-3dca-4068-817f-f24ee3b9d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and predict for regression\n",
    "# Create X and y arrays\n",
    "X = sales_df.drop(\"sales\", axis=1).values\n",
    "y = sales_df[\"sales\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate the model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"Predictions: {}, Actual Values: {}\".format(y_pred[:2], y_test[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d70e4-0998-44ea-93e8-5b8c38c2ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression preformance\n",
    "# Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Compute R-squared\n",
    "r_squared = reg.score(X_test, y_test)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"R^2: {}\".format(r_squared))\n",
    "print(\"RMSE: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c02d03e-4e11-4fd9-a6e2-5cee01899b90",
   "metadata": {},
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c3fcc3-4021-483f-ad15-e826ac937f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for R-squared\n",
    "\n",
    "# Import the necessary modules\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=5)\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Compute 6-fold cross-validation scores\n",
    "cv_scores = cross_val_score(reg, X, y, cv=kf)\n",
    "\n",
    "# Print scores\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d7e7c4-7acb-4832-9135-72ef850753f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing cross-validation metrics\n",
    "\n",
    "# Print the mean\n",
    "print(np.mean(cv_results))\n",
    "\n",
    "# Print the standard deviation\n",
    "print(np.std(cv_results))\n",
    "\n",
    "# Print the 95% confidence interval\n",
    "print(np.quantile(cv_results, [0.025, 0.975]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6818208a-865d-40b1-9092-f98109387330",
   "metadata": {},
   "source": [
    "#### Regularized regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dcf45a-2bd7-4da3-a84c-7ce21d02d922",
   "metadata": {},
   "source": [
    "* Ridge\n",
    "  * Ridge regression performs regularization by computing the squared values of the model parameters multiplied by alpha and adding them to the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c9ac6d-032e-4daf-a55b-4ddc769396c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularized regression: Ridge\n",
    "\n",
    "# Import Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "alphas = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
    "ridge_scores = []\n",
    "for alpha in alphas:\n",
    "  \n",
    "  # Create a Ridge regression model\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "  \n",
    "  # Fit the data\n",
    "    ridge.fit(X_train, y_train)\n",
    "  \n",
    "  # Obtain R-squared\n",
    "    score = ridge.score(X_test, y_test)\n",
    "    ridge_scores.append(score)\n",
    "print(ridge_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4681d989-36ec-453c-937e-625a61ee673b",
   "metadata": {},
   "source": [
    "* Lasso\n",
    "  * Lasso can select important features of a dataset (because shrinks the coefficients of less important features to zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802db786-d90d-4800-a2fb-14fc09fbea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression for feature importance\n",
    "\n",
    "# Import Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Instantiate a lasso regression model\n",
    "lasso = Lasso(alpha=0.3)\n",
    "\n",
    "# Fit the model to the data\n",
    "lasso.fit(X, y)\n",
    "\n",
    "# Compute and print the coefficients\n",
    "lasso_coef = lasso.fit(X, y).coef_\n",
    "print(lasso_coef)\n",
    "plt.bar(sales_columns, lasso_coef)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd90732-2bb3-42b2-a32e-67cd94755fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d92791b-e8cc-4634-b78a-7ac30d18df09",
   "metadata": {},
   "source": [
    "### (3) Fine-Tuing Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4024c6eb-c3fb-4972-b936-407eaeae16a4",
   "metadata": {},
   "source": [
    "#### Assessing a diabetes prediction classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b371fb-073b-4e4b-8f2c-80c07a7df181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e3e330-29b6-4b37-baa7-d051711d39b2",
   "metadata": {},
   "source": [
    "#### Building a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bcac12-af66-4eac-b399-4a77aff1204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(y_pred_probs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8423211c-e3c3-4bfb-aa1d-1d0f22cafd78",
   "metadata": {},
   "source": [
    "#### The ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e173092-0af2-4740-b401-08b5045025b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import roc_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# Plot tpr against fpr\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Diabetes Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dc35f0-d9c6-45da-9410-450d7c2ff174",
   "metadata": {},
   "source": [
    "#### ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d300201-4c6f-45df-a98e-cc5d013fa96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate roc_auc_score\n",
    "print(roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076c806-6172-4652-8953-ae6eccb5e3f3",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630054d-343b-4683-a353-53b865a35cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\"alpha\": np.linspace(0.00001, 1, 20)}\n",
    "\n",
    "# Instantiate lasso_cv\n",
    "lasso_cv = GridSearchCV(Lasso(), param_grid, cv=kf)\n",
    "\n",
    "# Fit to the training data\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "print(\"Tuned lasso paramaters: {}\".format(lasso_cv.best_params_))\n",
    "print(\"Tuned lasso score: {}\".format(lasso_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad5b4e8-172b-430a-8716-fef61e81710a",
   "metadata": {},
   "source": [
    "#### Hyperparameter uning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c77d5-e1fc-4b1c-aec8-7c7056507964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter space\n",
    "params = {\"penalty\": [\"l1\", \"l2\"],\n",
    "         \"tol\": np.linspace(0.0001, 1.0, 50),\n",
    "         \"C\": np.linspace(0.1, 1.0, 50),\n",
    "         \"class_weight\": [\"balanced\", {0:0.8, 1:0.2}]}\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "logreg_cv = RandomizedSearchCV(logreg, params, cv=kf)\n",
    "\n",
    "# Fit the data to the model\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Best Accuracy Score: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de98e3e-130a-4548-b36c-d10280258dc5",
   "metadata": {},
   "source": [
    "## (4) Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290d3e2-c18e-4095-9912-78d452d67f0d",
   "metadata": {},
   "source": [
    "#### Creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5405c-63e4-4514-ac6e-fd11791f751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create music_dummies\n",
    "music_dummies = pd.get_dummies(music_df, drop_first=True)\n",
    "\n",
    "# Print the new DataFrame's shape\n",
    "print(\"Shape of music_dummies: {}\".format(music_dummies.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b016f65-c73c-4594-8f5c-de509f238fd0",
   "metadata": {},
   "source": [
    "#### Regression with categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f307f-e2f0-4ba5-a012-9e561face7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "X = music_dummies.drop(columns='popularity', axis=1).values\n",
    "y = music_dummies['popularity'].values\n",
    "\n",
    "# Instantiate a ridge model\n",
    "ridge = Ridge(alpha=0.2)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")  # https://ai.stackexchange.com/questions/9022/can-the-mean-squared-error-be-negative\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(-scores)\n",
    "print(\"Average RMSE: {}\".format(np.mean(rmse)))\n",
    "print(\"Standard Deviation of the target array: {}\".format(np.std(y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0011071-6eac-4363-848d-e5e496297113",
   "metadata": {},
   "source": [
    "#### Droping missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf9e8f-1ab9-47fd-8fe7-3cfbcd6ff48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n",
    "\n",
    "# Convert genre to a binary feature\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "print(music_df.isna().sum().sort_values())\n",
    "print(\"Shape of the `music_df`: {}\".format(music_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8a0b3f-bf15-4587-af35-7d3c3f7e0155",
   "metadata": {},
   "source": [
    "#### Pipeline for song genre prediction: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a443a8b1-aeec-4742-8c58-3543c715c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Instantiate an imputer\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "# Instantiate a knn model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Build steps for the pipeline\n",
    "steps = [(\"imputer\", imputer), \n",
    "         (\"knn\", knn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaeb48e-9c08-49f5-b9be-f6a2862c6ec2",
   "metadata": {},
   "source": [
    "#### Pipeline for song genre prediction: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55f8f8-7d5f-42c6-806c-bf58d4219a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [(\"imputer\", imp_mean),\n",
    "        (\"knn\", knn)]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d40dd-a756-4c39-92dc-b9f7402ccf4e",
   "metadata": {},
   "source": [
    "#### Centering and scaling (Centering and scaling for regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26360245-82ee-4c8b-8bd1-9e1d3fc4794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create pipeline steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"lasso\", Lasso(alpha=0.5))]\n",
    "\n",
    "# Instantiate the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate and print R-squared\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9ed01-1bd5-4137-8ccc-2c0284d3b94f",
   "metadata": {},
   "source": [
    "#### Centering and scaling for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa7dec4-a713-4058-91e3-116712997fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"logreg\", LogisticRegression())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create the parameter space\n",
    "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}                          # 모델의 하이퍼파라미터 name = \"logreg__C\"로 해야 함\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "# Instantiate the grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c523f6-c3f6-4a41-b8f9-3d77bc7e744f",
   "metadata": {},
   "source": [
    "#### Evaluating multiple models (Visualizing regression model performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ea8bbf-78c0-44af-8dc2-475d0019e66a",
   "metadata": {},
   "source": [
    "* 상황마다 사용해야 하는 모델은 다름\n",
    "* 기능이 적을수록 더 간단하고 빠름 (+ 해석 가능한 모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30cf1a-e849-499e-b66d-37cc860925e1",
   "metadata": {},
   "source": [
    "It's all in the metrics\n",
    "* Regression model performance:\n",
    "    * RMSE\n",
    "    * R-squared\n",
    "* Classification model performance:\n",
    "    * Accuracy\n",
    "    * Confusion matrix\n",
    "    * Precision, recall, F1-score\n",
    "    * ROC AUC  \n",
    "  \n",
    "A note on scaling\n",
    "* Models affected by scaling\n",
    "    * KNN\n",
    "    * Linear Regression (+ Ridge, Lasso)\n",
    "    * Logistic Regression\n",
    "    * Artificiai Neural Network\n",
    "* Best to scale our data before evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee73803-d653-4cc6-adcf-4111259777a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "  \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "  \n",
    "    # Append the results\n",
    "    results.append(cv_scores)\n",
    "\n",
    "# Create a box plot of the results\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7f662-8ec9-40b2-a739-89d831651c73",
   "metadata": {},
   "source": [
    "#### Predicting on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e022e-3ea4-4db5-af70-2292123107f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for name, model in models.items():\n",
    "  \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate the test_rmse\n",
    "    test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    print(\"{} Test Set RMSE: {}\".format(name, test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e08a43-fbef-4723-aff5-22f17173f4b1",
   "metadata": {},
   "source": [
    "#### Visualizing classification model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f728fb8-33e2-4997-b922-3b665ce68676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \"KNN\": KNeighborsClassifier(), \"Decision Tree Classifier\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  \n",
    "    # Instantiate a KFold object\n",
    "    kf = KFold(n_splits=6, random_state=12, shuffle=True)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "    results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b3d41e-a9eb-417a-89cf-0d5c3629af7d",
   "metadata": {},
   "source": [
    "#### Pipeline for predicting song popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a6557-b798-4399-b748-8554ce779db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create steps\n",
    "steps = [(\"imp_mean\", SimpleImputer()), \n",
    "         (\"scaler\", StandardScaler()), \n",
    "         (\"logreg\", LogisticRegression())]\n",
    "\n",
    "# Set up pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "params = {\"logreg__solver\": [\"newton-cg\", \"saga\", \"lbfgs\"],\n",
    "         \"logreg__C\": np.linspace(0.001, 1.0, 10)}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "tuning = GridSearchCV(pipeline, param_grid=params)\n",
    "tuning.fit(X_train, y_train)\n",
    "y_pred = tuning.predict(X_test)\n",
    "\n",
    "# Compute and print performance\n",
    "print(\"Tuned Logistic Regression Parameters: {}, Accuracy: {}\".format(tuning.best_params_, tuning.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc021b3-beb8-482c-9739-8a6855b055f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 이론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865871ba-8e38-4a5a-819e-5859261f5e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69abd280-771e-4e14-b6c4-8b3269d201a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4259b0d-c749-40af-aba4-7177397fa087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30251cbe-3597-48ef-8e11-0ffabdd9e701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c58e4b-d4db-4c07-a9e8-865b6e4a5011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e08cb6-cb1c-4eb1-8e1f-5a4e6ec2e7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08056ea8-7999-4118-b14f-b15205c9835b",
   "metadata": {},
   "source": [
    "## (3) Fine-Tuning Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493299f0-2b20-488d-a455-58334262747f",
   "metadata": {},
   "source": [
    "* 오차율, 정확도(accuracy)는 분류 분석에서 가장 자주 사용하는 2가지 성능척도. 이진 분류 뿐만 아니라 다중 분류에서도 자주 사용.  \n",
    "    - 오차율 : 모든 샘플 수에서 잘못 분류한 샘플 수가 차지하는 비율\n",
    "    - 정확도 : 전체 샘플 수에서 정확히 분류한 샘플 수가 차지하는 비율\n",
    "* 오차율, 정확도는 자주 사용되지만 모든 문제에 활용되진 못함. \n",
    "    - ex) 수박 장수가 수박을 손수레에 가득 담아 왔다. 그는 훈련된 모델을 통해 수박들을 분류하려고 하는데 여기서 오차율은 덜 익은 수박으로 분류되는 판별 오차율을 나타낼 수 있다. 그러나, 우리가 알고자 하는 건 '골라낸 수박 중에 잘 익은 수박의 비율', 혹은 '모든 잘 익은 수박 중 선택될 비율'이다. 여기서 오차율은 도움을 줄 수 없다.\n",
    "    - ex) 정보 검색 중 일반적으로 확인하고자 하는 건 '검색된 자료 중 내가 관심있어 할 내용의 비율'이다.  \n",
    "\n",
    "* 정밀도(precision)와 재현율(recall)이 이러한 요구에 맞는 성능 척도.  \n",
    "    - 이진 분류 문제에서 실제 클래스와 학습기가 예측 분류한 클래스의 조합은 실제양성(true positive), 거짓양성(false positive), 실제음성(true negative), 거짓음성(false negative) 총 4가지로 요약\n",
    "    - 각각 TP, FP, TN, FN으로 나타내며 TP + FP + TN + FN = 총 샘플 수'이다.\n",
    "    - 이러한 분류 결과를 혼동행렬(confusion matrix)라고 함\n",
    "        - 정밀도: 양성 예측의 정확도. TP / TP + FP\n",
    "        - 재현율: 분류기가 정확하게 감지한 양성 샘플의 비율 (민감도 sensitivity, 진짜 양성 비율 true positive rate(TPR) 이라고도 함). TP / TP + FN\n",
    "* F1-Score\n",
    "    - 정밀도와 재현율을 하나의 숫자로 만든 것\n",
    "    - 정밀도와 재현율의 조화평균\n",
    "    - F1 = 2 / (1/정밀도 + 1/재현율) = 2 * (정밀도 * 재현율 / 정밀도 + 재현율) = TP / (TP + (FN + FP) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ea8df-0b9f-40d9-9fbb-576a53a11535",
   "metadata": {},
   "source": [
    "* Logistic regresson 을 활용한 평가\n",
    "* ROC Curve (receiver operating characterstic Curve)\n",
    "    * 이진 분류에서 많이 사용\n",
    "    * 정밀도에 대한 재현율 곡선이 아님. 거짓 양성 비율(False positive rate, FPR)에 대한 진짜 양성 비율(True positive rate, TPR)의 곡선\n",
    "        * FPR = 양성으로 잘못 분류된 음성 샘풀의 비율. 1 - TNR (음성으로 정확하게 분류한 음성 샘플의 비율)\n",
    "            * TNR = 특이도(speicificity)라고도 함\n",
    "    * 즉, ROC 곡선은 민감도(재현율)에 대한 1-특이도 그래프\n",
    "    * ROC 곡선이 좌측 하단과 우측 상단을 이은 직선에 가까울수록 성능이 떨어지는 것이며, 멀어질수록 성능이 뛰어난 것\n",
    "* ROC AUC\n",
    "    * 곡선 아래의 면적(area under the curve)을 측정하면 분류기들을 비교할 수 있음\n",
    "    * 완벽한 분류기는 ROC의 AUC가 1, 완전한 랜덤 분류기는 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0060f9-7ae3-4457-98b5-189344362a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6088ddde-4e73-4144-bb1c-8fdc1e685a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e599d163-0ca3-4830-9b64-b8fcef57f380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c949cda-e5e4-47ae-b3e5-1b17ee09c557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03e5d240-6eb3-4b7c-ae57-8bdb6a12f974",
   "metadata": {},
   "source": [
    "# 실습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fc7b8e-8e70-43f9-9bbb-04fe9efe8112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
