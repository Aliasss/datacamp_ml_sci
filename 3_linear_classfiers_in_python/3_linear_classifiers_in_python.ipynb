{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb5af95-d3e6-4fe1-8c64-4d2a701cd721",
   "metadata": {},
   "source": [
    "# Applying logistic regression and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2e04f-527f-401a-b11d-fd2deca85b69",
   "metadata": {},
   "source": [
    "## scikit-learn refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bcff05-cda2-4e75-9571-48213e1f90e5",
   "metadata": {},
   "source": [
    "### KNN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd8b1f-abe4-4b64-8608-3087b90ea2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create and fit the model\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test features, print the results\n",
    "pred = knn.predict(X_test)[0]\n",
    "print(\"Prediction for test example 0:\", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aac70b-9e4c-4a04-9e22-629af1f78731",
   "metadata": {},
   "source": [
    "## Applying Logistic regression and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4374aae0-9ec1-4242-b3f1-16603198cb37",
   "metadata": {},
   "source": [
    "### Running LogisticRegression and SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f59953-0055-48a2-b54c-abb658ab5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target)\n",
    "\n",
    "# Apply logistic regression and print scores\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.score(X_train, y_train))\n",
    "print(lr.score(X_test, y_test))\n",
    "\n",
    "# Apply SVM and print scores\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "print(svm.score(X_train, y_train))\n",
    "print(svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f473e-909c-4a4a-a85e-f9300cb6e722",
   "metadata": {},
   "source": [
    "### Sentiment analysis for movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365077e1-681f-4982-9ba5-e2e240a463a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate logistic regression and train\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Predict sentiment for a glowing review\n",
    "review1 = \"I'm very happy now!\"\n",
    "review1_features = get_features(review1)\n",
    "print(\"Review:\", review1)\n",
    "print(\"Probability of positive review:\", lr.predict_proba(review1_features)[0,1])\n",
    "\n",
    "# Predict sentiment for a poor review\n",
    "review2 = \"It's so terrible.\"\n",
    "review2_features = get_features(review2)\n",
    "print(\"Review:\", review2)\n",
    "print(\"Probability of positive review:\", lr.predict_proba(review2_features)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fcb396-a379-44f4-b9ea-e6905b074435",
   "metadata": {},
   "source": [
    "## Linear Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f16d3-9a12-434d-b6e6-60bf49c00150",
   "metadata": {},
   "source": [
    "### Visualizing decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dbbd33-f23a-409d-8cce-c9dd228e86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the classifiers\n",
    "classifiers = [LogisticRegression() ,LinearSVC(), SVC(), KNeighborsClassifier()]\n",
    "\n",
    "# Fit the classifiers\n",
    "for c in classifiers:\n",
    "    c.fit(X, y)\n",
    "\n",
    "# Plot the classifiers\n",
    "plot_4_classifiers(X, y, classifiers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61826c2-0d5c-46d6-9ef4-c7200238056c",
   "metadata": {},
   "source": [
    "![img](visualizing_decision_boundary.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f9a94a-1a6d-4bc7-9a4c-8c918e5ff8b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910e9d01-e598-4601-9a87-09c3d7d7dade",
   "metadata": {},
   "source": [
    "## Linear classifiers: the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6b6c52-000a-4f1a-8d7c-d3ca6f074bcf",
   "metadata": {},
   "source": [
    "### How models make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc76b1f-11b0-4ef9-be24-9a52e151895d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f42c085-81a2-4796-bd49-58ade761b6b8",
   "metadata": {},
   "source": [
    "### Changing the model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8970b8df-410b-4e0f-a211-d3a0b4e8280e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "440e6a15-642a-4c0a-a63f-30094333c925",
   "metadata": {},
   "source": [
    "## What is a loss function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1359864f-e3b5-4bf6-8fd1-1b98fb0ed9d2",
   "metadata": {},
   "source": [
    "### The 0-1 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c35ed8-a746-4715-b00e-11eab07e5430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d90cee28-3b52-48ce-ab30-d77f51389fde",
   "metadata": {},
   "source": [
    "### Minimizing a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6855f9-625e-44e9-ae1b-9c8343a10d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e49f5ad-0afa-44d1-ae95-6e5bc4317475",
   "metadata": {},
   "source": [
    "## Loss function diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8aa26a-2e13-446f-b19d-4affbfe4807f",
   "metadata": {},
   "source": [
    "### Classification loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22072ed4-43b6-41b4-9541-dba360deec4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fca69b6e-d662-446f-a55f-ed4d597a5823",
   "metadata": {},
   "source": [
    "### Comparing the logistic and hinge losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7dc5a6-24ad-45a6-a33f-656b390f87c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b778efce-9579-43a4-a95e-edd19365115b",
   "metadata": {},
   "source": [
    "### Implementing logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b495413-8621-4524-ab82-1df2e681ccdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30c69193-2f5a-4309-b332-82b23a002a06",
   "metadata": {},
   "source": [
    "# Logistic regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66755404-020b-4172-a75f-bed3a805cbe3",
   "metadata": {},
   "source": [
    "## Logistic regression and regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243b0a7-e5a0-4e72-851c-1b04fe795b54",
   "metadata": {},
   "source": [
    "### Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16841b54-c3d8-4d8c-8566-0a443a5fa11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validaton errors initialized as empty list\n",
    "train_errs = list()\n",
    "valid_errs = list()\n",
    "\n",
    "# Loop over values of C_value\n",
    "for C_value in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    # Create LogisticRegression object and fit\n",
    "    lr = LogisticRegression(C=C_value)\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate error rates and append to lists\n",
    "    train_errs.append( 1.0 - lr.score(X_train, y_train) )\n",
    "    valid_errs.append( 1.0 - lr.score(X_valid, y_valid) )\n",
    "    \n",
    "# Plot results\n",
    "plt.semilogx(C_values, train_errs, C_values, valid_errs)\n",
    "plt.legend((\"train\", \"validation\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534fc269-4a33-46a5-8537-3ff17a942d6f",
   "metadata": {},
   "source": [
    "![img](Regularized_logistic_regression.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6a298-1bf4-4bb8-a3c3-9ccd12d7f2bf",
   "metadata": {},
   "source": [
    "* C = Inverse regularization strength\n",
    "    * Lidge, Lasso의 alpha의 역방향\n",
    "        * Lidge, Lasso의 alpha가 증가할수록 Regularization 강도가 강해지므로 회귀 계수 값을 감소시키고 Overfitting 개선함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da8b2f7-3920-47fe-bf41-8a7719b19418",
   "metadata": {},
   "source": [
    "### Logistic regression and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099a377-ee54-4558-8f3c-2f9b3e3a192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify L1 regularization\n",
    "lr = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "\n",
    "# Instantiate the GridSearchCV object and run the search\n",
    "searcher = GridSearchCV(lr, {'C':[0.001, 0.01, 0.1, 1, 10]})\n",
    "searcher.fit(X_train, y_train)\n",
    "\n",
    "# Report the best parameters\n",
    "print(\"Best CV params\", searcher.best_params_)\n",
    "\n",
    "# Find the number of nonzero coefficients (selected features)\n",
    "best_lr = searcher.best_estimator_\n",
    "coefs = best_lr.coef_\n",
    "print(\"Total number of features:\", coefs.size)\n",
    "print(\"Number of selected features:\", np.count_nonzero(coefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f98433-c5b8-4d92-a8e1-207ccf0bc1df",
   "metadata": {},
   "source": [
    "![img](Logistic_regression_feature_selection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec65569-6039-49c6-96ca-64a127b5444c",
   "metadata": {},
   "source": [
    "### Identifying the most positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31c668-ba2a-439d-aaac-2788bd190b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the sorted cofficients\n",
    "inds_ascending = np.argsort(lr.coef_.flatten()) \n",
    "inds_descending = inds_ascending[::-1]\n",
    "\n",
    "# Print the most positive words\n",
    "print(\"Most positive words: \", end=\"\")\n",
    "for i in range(5):\n",
    "    print(vocab[inds_descending[i]], end=\", \")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print most negative words\n",
    "print(\"Most negative words: \", end=\"\")\n",
    "for i in range(5):\n",
    "    print(vocab[inds_ascending[i]], end=\", \")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635797b-8ac7-473c-a8c9-592c9e2e0400",
   "metadata": {},
   "source": [
    "## Logistic regression and probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b1ab87-1f01-47ab-8c03-360e2db53adb",
   "metadata": {},
   "source": [
    "### Regularization and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed38d65-a091-4d72-8bda-25f86cc86884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 1\n",
    "# Set the regularization strength\n",
    "model = LogisticRegression(C=1)\n",
    "\n",
    "# Fit and plot\n",
    "model.fit(X,y)\n",
    "plot_classifier(X,y,model,proba=True)\n",
    "\n",
    "# Predict probabilities on training points\n",
    "prob = model.predict_proba(X)\n",
    "print(\"Maximum predicted probability\", np.max(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f75dd1-7f0b-4180-97e2-653aba7dd214",
   "metadata": {},
   "source": [
    "![a](regularization_and_probaility1.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8524b-811c-433e-9d28-d110b2b9292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 0.1\n",
    "# Set the regularization strength\n",
    "model = LogisticRegression(C=0.1)\n",
    "\n",
    "# Fit and plot\n",
    "model.fit(X,y)\n",
    "plot_classifier(X,y,model,proba=True)\n",
    "\n",
    "# Predict probabilities on training points\n",
    "prob = model.predict_proba(X)\n",
    "print(\"Maximum predicted probability\", np.max(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb021c-5acf-46d9-9376-29340aee2e18",
   "metadata": {},
   "source": [
    "![a](regularization_and_probability_2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8944e533-e0f8-4488-a025-5061714b0bec",
   "metadata": {},
   "source": [
    "* C를 낮췄더니 train data에 대한 예측력이 낮아짐  \n",
    "As you probably noticed, smaller values of C lead to less confident predictions. That's because smaller C means more regularization, which in turn means smaller coefficients, which means raw model outputs closer to zero and, thus, probabilities closer to 0.5 after the raw model output is squashed through the sigmoid function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d2d19c-bb71-4483-92fd-fc266a70b2cf",
   "metadata": {},
   "source": [
    "### Visualizing easy and difficult examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bff28ae-a5bf-4049-a4c6-ccc8515b5ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X,y)\n",
    "\n",
    "# Get predicted probabilities\n",
    "proba = lr.predict_proba(X)\n",
    "\n",
    "# Sort the example indices by their maximum probability\n",
    "proba_inds = np.argsort(np.max(proba,axis=1))\n",
    "\n",
    "# Show the most confident (least ambiguous) digit\n",
    "show_digit(proba_inds[-1], lr)\n",
    "\n",
    "# Show the least confident (most ambiguous) digit\n",
    "show_digit(proba_inds[0], lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4423ed33-f475-431f-b668-9db13aa00476",
   "metadata": {},
   "source": [
    "## Multi-class logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad05a224-ae04-4e62-9880-33e94da7ba42",
   "metadata": {},
   "source": [
    "### Fitting multi-class logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845bd68-0261-4248-b6e7-7bd5e6d4adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit one-vs-rest logistic regression classifier\n",
    "lr_ovr = LogisticRegression(multi_class='ovr')\n",
    "lr_ovr.fit(X_train, y_train)\n",
    "\n",
    "print(\"OVR training accuracy:\", lr_ovr.score(X_train, y_train))\n",
    "print(\"OVR test accuracy    :\", lr_ovr.score(X_test, y_test))\n",
    "\n",
    "# Fit softmax classifier\n",
    "lr_mn = LogisticRegression(multi_class='multinomial')\n",
    "lr_mn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Softmax training accuracy:\", lr_mn.score(X_train, y_train))\n",
    "print(\"Softmax test accuracy    :\", lr_mn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfce496-3841-49cc-b71c-3ee816f13db0",
   "metadata": {},
   "source": [
    "### Visualizing multi-class logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9afd0f-39ab-4fc0-867c-53c146f2c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print training accuracies\n",
    "print(\"Softmax     training accuracy:\", lr_mn.score(X_train, y_train))\n",
    "print(\"One-vs-rest training accuracy:\", lr_ovr.score(X_train, y_train))\n",
    "\n",
    "# Create the binary classifier (class 1 vs. rest)\n",
    "lr_class_1 = LogisticRegression(C=100)\n",
    "lr_class_1.fit(X_train, y_train==1)\n",
    "\n",
    "# Plot the binary classifier (class 1 vs. rest)\n",
    "plot_classifier(X_train, y_train==1, lr_class_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb7982-6ac0-4dcc-91d8-ee2edc0e26b0",
   "metadata": {},
   "source": [
    "### One-vs-rest SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ace3cd-92b7-4316-b566-dbe81859ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use SVC instead of LinearSVC from now on\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create/plot the binary classifier (class 1 vs. rest)\n",
    "svm_class_1 = SVC()\n",
    "svm_class_1.fit(X_train, y_train==1)\n",
    "plot_classifier(X_train, y_train==1, svm_class_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0703c8ae-b868-4044-97a3-ca55431e98f3",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c2512-6223-4eed-b292-aec44d5dab47",
   "metadata": {},
   "source": [
    "## Support vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82aa6db-6c71-4206-9bc0-03c04831ca11",
   "metadata": {},
   "source": [
    "### Support vector definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9c0a25-fbbd-452b-a326-dcefb0bde02d",
   "metadata": {},
   "source": [
    "Which of the following is a true statement about support vectors? To help you out, here's the picture of support vectors from the video (top), as well as the hinge loss from Chapter 2 (bottom).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2fd56c-9c16-4eb7-84c4-6a7761294018",
   "metadata": {},
   "source": [
    "![1](svm_defi_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be8e5c6-bcd0-4a77-b971-d4596768e300",
   "metadata": {},
   "source": [
    "![b](svm_defi_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcdb7c3-f7e7-4319-9d65-6aafe1dc8d22",
   "metadata": {},
   "source": [
    "* answer: All incorrectly classified points are support vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c42944-8d00-41ed-a9f5-29d3cb8d6df1",
   "metadata": {},
   "source": [
    "### Effect of removing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91a02e-b08c-4ba4-9dc5-85ac517935b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a linear SVM\n",
    "svm = SVC(kernel=\"linear\")\n",
    "svm.fit(X,y)\n",
    "plot_classifier(X, y, svm, lims=(11,15,0,6))\n",
    "\n",
    "# Make a new data set keeping only the support vectors\n",
    "print(\"Number of original examples\", len(X))\n",
    "print(\"Number of support vectors\", len(svm.support_))\n",
    "X_small = X[svm.support_]\n",
    "y_small = y[svm.support_]\n",
    "\n",
    "# Train a new SVM using only the support vectors\n",
    "svm_small = SVC(kernel=\"linear\")\n",
    "svm_small.fit(X_small, y_small)\n",
    "plot_classifier(X_small, y_small, svm_small, lims=(11,15,0,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9098daac-4473-4704-953b-73fb849a5786",
   "metadata": {},
   "source": [
    "![1](svm1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e18aaa-a13d-4907-a388-9c276d1c4c01",
   "metadata": {},
   "source": [
    "## Kernel SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92be0e8-e573-4cf4-8abd-1e4177fdfa8c",
   "metadata": {},
   "source": [
    "* SVC(gamma=)\n",
    "    * smaller **gamma** leads to smoother boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3cdd09-ed7e-4303-8d38-86344fef4060",
   "metadata": {},
   "source": [
    "### GridSearchCV warm-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270dd77c-cb04-4c81-aa30-1b210351bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an RBF SVM\n",
    "svm = SVC(kernel='rbf') # kernel default = 'rbf'\n",
    "\n",
    "# Instantiate the GridSearchCV object and run the search\n",
    "parameters = {'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
    "searcher = GridSearchCV(svm, parameters)\n",
    "searcher.fit(X, y)\n",
    "\n",
    "# Report the best parameters\n",
    "print(\"Best CV params\", searcher.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d39c594-36a8-4e25-9f5c-17d2dfe3997d",
   "metadata": {},
   "source": [
    "### Jointly tuning gamma and C with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd8471-8ef8-48da-a994-d6086ec86754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an RBF SVM\n",
    "svm = SVC()\n",
    "\n",
    "# Instantiate the GridSearchCV object and run the search\n",
    "parameters = {'C':[0.1, 1, 10], 'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
    "searcher = GridSearchCV(svm, parameters)\n",
    "searcher.fit(X_train, y_train)\n",
    "\n",
    "# Report the best parameters and the corresponding score\n",
    "print(\"Best CV params\", searcher.best_params_)\n",
    "print(\"Best CV accuracy\", searcher.best_score_)\n",
    "\n",
    "# Report the test accuracy using these best parameters\n",
    "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3008e2bc-c366-4bd7-b048-c42f48f00bb9",
   "metadata": {},
   "source": [
    "## Comparing logistic regression and SVM (and beyond)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac0bd9d-1a17-450c-b3a9-bd84b6a011a3",
   "metadata": {},
   "source": [
    "### An advantage of SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc1b1a-f8f4-4e28-a978-e7ab57ae9e2c",
   "metadata": {},
   "source": [
    "![1](logi_svm1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986a9177-994f-4e29-90d0-05d94c0f579b",
   "metadata": {},
   "source": [
    "![2](logi_svm2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ed305f-1a03-4f79-a7d5-f3a928d69027",
   "metadata": {},
   "source": [
    "![3](logi_svm3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8472d-19fd-420b-9b9e-f9e81053a691",
   "metadata": {},
   "source": [
    "Which of the following is an advantage of SVMs over logistic regression?\n",
    "\n",
    "* The answer is : Having a limited number of support vectors makes kernel SVMs computationally efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f645a-f4a6-4329-a84a-2f12b27a47e6",
   "metadata": {},
   "source": [
    "### An advantage of logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b92a3e-b8ee-4d4d-b6dd-820f142374d2",
   "metadata": {},
   "source": [
    "Which of the following is an advantage of logistic regression over SVMs?\n",
    "\n",
    "* The answer is : It naturally outputs meaningful probabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32ee9e4-516e-417d-94f0-c39633488918",
   "metadata": {},
   "source": [
    "### Using SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e642af6e-05ab-4fc3-b2f7-42f382b40fa3",
   "metadata": {},
   "source": [
    "![sgd](sgd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b2fbc7-b02a-49a2-a057-58135531e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set random_state=0 for reproducibility \n",
    "linear_classifier = SGDClassifier(random_state=0)\n",
    "\n",
    "# Instantiate the GridSearchCV object and run the search\n",
    "parameters = {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \n",
    "             'loss':['hinge', 'log_loss']}\n",
    "searcher = GridSearchCV(linear_classifier, parameters, cv=10)\n",
    "searcher.fit(X_train, y_train)\n",
    "\n",
    "# Report the best parameters and the corresponding score\n",
    "print(\"Best CV params\", searcher.best_params_)\n",
    "print(\"Best CV accuracy\", searcher.best_score_)\n",
    "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f463188-0234-4123-b6e2-bf23cd921ea2",
   "metadata": {},
   "source": [
    "![sgd](hinge_log_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be71320-3ac6-419c-9ff0-a128153961bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cdeddf-fb85-4360-8a99-5dd0e5e1992e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
